{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File /Users/joshtitlow/Desktop/airyscan_smFISH_data/20180910_SypeGFP_rRNA_msp_smFISH_stim/aligned/smFISH_channel/_batch/_FISH-QUANT__all_spots_180913.txt does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-adc654dac2c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;31m# read the FQ file from the metadata header to get pixel size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mpx_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFQ_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0mpx_xy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pix-XY'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0mpx_z\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpx_size\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pix-Z'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, skip_footer, doublequote, delim_whitespace, as_recarray, compact_ints, use_unsigned, low_memory, buffer_lines, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    560\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    314\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 315\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    643\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 645\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    646\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 799\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    800\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    801\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1211\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1213\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1214\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1215\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3427)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6861)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File /Users/joshtitlow/Desktop/airyscan_smFISH_data/20180910_SypeGFP_rRNA_msp_smFISH_stim/aligned/smFISH_channel/_batch/_FISH-QUANT__all_spots_180913.txt does not exist"
     ]
    }
   ],
   "source": [
    "# Script to extract pixel intensities relative to centroid coordinates\n",
    "# created: 9 August 2018\n",
    "# revised: 4 September 2018\n",
    "# original code in pixel_heatmaps.py\n",
    "#\n",
    "# REQUIRES:\n",
    "# specify a directory of images\n",
    "# specify centroid file ('_FISH-QUANT_all_spots_yymmdd.csv') from a FQ bash run\n",
    "# specify the data channel\n",
    "#\n",
    "# TO DO:\n",
    "# Install arg parse\n",
    "#    > arguments = centroid file, ch, image dir\n",
    "\n",
    "import os\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "\n",
    "# specify image directory\n",
    "image_dir ='/Users/joshtitlow/Desktop/airyscan_smFISH_data/20180910_SypeGFP_rRNA_msp_smFISH_stim/aligned/'\n",
    "\n",
    "# specify data channel\n",
    "data_ch = 0 # specify the correct data channel\n",
    "\n",
    "# specify the FQ centroid file\n",
    "FQ_file = '/Users/joshtitlow/Desktop/airyscan_smFISH_data/20180910_SypeGFP_rRNA_msp_smFISH_stim/aligned/smFISH_channel/_batch/_FISH-QUANT__all_spots_180913.txt'\n",
    "\n",
    "# read the FQ file from the metadata header to get pixel size\n",
    "px_size = pd.read_csv(FQ_file, sep='\\t', header=6, nrows=2)\n",
    "px_xy = px_size['Pix-XY'].iloc[0]\n",
    "px_z = px_size['Pix-Z'].iloc[0]\n",
    "\n",
    "# read the FQ file from the data header to get centroid positions\n",
    "centroid_file = pd.read_csv(FQ_file, sep='\\t', header=13)\n",
    "\n",
    "# convert spatial dimensions to pixel dimensions\n",
    "centroid_file['X_pix'] = np.ceil(centroid_file['Pos_X'].div(float(px_xy)))\n",
    "centroid_file['Y_pix'] = np.ceil(centroid_file['Pos_Y'].div(float(px_xy)))\n",
    "centroid_file['Z_pix'] = np.ceil(centroid_file['Pos_Z'].div(float(px_z)))\n",
    "\n",
    "# create lists to store pixel intensity values\n",
    "mean_pixels = []\n",
    "min_pixels = []\n",
    "max_pixels = []\n",
    "\n",
    "# setup a figure\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "\n",
    "# start counting so the plt\n",
    "n = 1\n",
    "\n",
    "# index rows in the FQ.csv file to get file names and pixel coordinates\n",
    "for index, row in centroid_file.iterrows():\n",
    "\n",
    "    # get file name from File column\n",
    "    image  = row['File']\n",
    "\n",
    "    # open the image using sci kit image\n",
    "    im = io.imread(image_dir+image.replace('-1.tif', '.tif'))\n",
    "    #print image.replace('-1.tif', '.tif'), im.shape \n",
    "    \n",
    "    # store pixel coordinates (3x3 matrix surrounding the centroid) as variables\n",
    "    Y = row['Y_pix']\n",
    "    X = row['X_pix']\n",
    "    Z = np.absolute(row['Z_pix']-1)\n",
    "    x0 = row['X_pix'] - 1\n",
    "    x1 = row['X_pix']\n",
    "    x2 = row['X_pix'] + 1\n",
    "    y0 = row['Y_pix'] - 1\n",
    "    y1 = row['Y_pix']\n",
    "    y2 = row['Y_pix'] + 1\n",
    "    \n",
    "    # generate a list of pixel values in the matrix\n",
    "    matrix_pixels = (im[data_ch,Z,x0,y0],im[data_ch,Z,x1,y0],im[data_ch,Z,x2,y0],im[data_ch,Z,x0,y1],im[data_ch,Z,x1,y1],\n",
    "                     im[data_ch,Z,x2,y1],im[data_ch,Z,x0,y2],im[data_ch,Z,x1,y2],im[data_ch,Z,x2,y2])\n",
    "    \n",
    "    # load pixel values into a numpy array and create a matrix\n",
    "    matrix = np.array(matrix_pixels)\n",
    "    data = matrix.reshape((3, 3))\n",
    "\n",
    "    # setup a figure (for single plots)\n",
    "    #fig = plt.figure(figsize = (1,0.5)) # this line is outside the loop for this script\n",
    "\n",
    "    # define subplot in that figure\n",
    "    #ax = fig.add_subplot(121) # numbers equal position of plot within the figure\n",
    "    ax = fig.add_subplot(50,50,n) # numbers equal position of plot within the figure\n",
    "\n",
    "    # modify the plot\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "\n",
    "    # define heatmap settings\n",
    "    heatmap = ax.pcolor(data, cmap=plt.cm.Greys, vmin=0, vmax=461)\n",
    "    heatmap.set_label('pixel intensity')\n",
    "\n",
    "    # plot heatmap\n",
    "    #plt.colorbar(heatmap)\n",
    "\n",
    "    # calculate some descriptive statistics on the intensity of pixels surrounding the centroid\n",
    "    pixelmean = np.mean(matrix_pixels)\n",
    "    pixelmin = np.min(matrix_pixels)\n",
    "    pixelmax = np.max(matrix_pixels)\n",
    "\n",
    "    # add pixel statistics to a list\n",
    "    mean_pixels.append(pixelmean)\n",
    "    min_pixels.append(pixelmin)\n",
    "    max_pixels.append(pixelmax)\n",
    "\n",
    "    # iterate\n",
    "    n+=1\n",
    "\n",
    "# calculate some basic stastistics about pixel intensity from the whole dataset\n",
    "meanpixel=np.mean(mean_pixels)\n",
    "minpixel=np.min(min_pixels)\n",
    "maxpixel=np.max(max_pixels)\n",
    "\n",
    "# print basic statistics from the whole dataset\n",
    "print \"Mean pixel intensity =\", meanpixel\n",
    "print \"Min pixel intensity =\", minpixel\n",
    "print \"Max pixel intensity =\", maxpixel\n",
    "\n",
    "# write basic statistics to centroid file\n",
    "centroid_file['mean_pix'] = mean_pixels\n",
    "\n",
    "#centroid_file = pd.DataFrame(mean_pixels, columns=[\"column\"])\n",
    "centroid_file.to_csv('test_list.csv', index=False)\n",
    "\n",
    "# plot figure and save\n",
    "plt.savefig('test_matrix.png')\n",
    "plt.show(fig)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Quarter</th>\n",
       "      <th>period</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2014</td>\n",
       "      <td>q1</td>\n",
       "      <td>https://omero1.bioch.ox.ac.uk/figure/file/2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>q3</td>\n",
       "      <td>https://omero1.bioch.ox.ac.uk/figure/file/2015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year Quarter                                          period\n",
       "0  2014      q1  https://omero1.bioch.ox.ac.uk/figure/file/2014\n",
       "1  2015      q3  https://omero1.bioch.ox.ac.uk/figure/file/2015"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame([[\"2014\", \"q1\"], [\"2015\", \"q3\"]], columns=('Year', 'Quarter'))\n",
    "df[\"period\"]=str('https://omero1.bioch.ox.ac.uk/figure/file/')+(df[\"Year\"])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 6, 956, 956)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import math\n",
    "\n",
    "fig = plt.figure(figsize = (10,10))\n",
    "    \n",
    "    # define subplot in that figure\n",
    "    #ax = fig.add_subplot(121) # numbers equal position of plot within the figure\n",
    "    ax = fig.add_subplot(50,50,n) # numbers equal position of plot within the figure\n",
    "\n",
    "    # modify the plot\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "    ax.spines['top'].set_visible(False)\n",
    "    ax.spines['bottom'].set_visible(False)\n",
    "    ax.spines['left'].set_visible(False)\n",
    "    ax.spines['right'].set_visible(False)\n",
    "    \n",
    "plt.show(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'amplitude' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-100857451c1c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamplitude\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbins\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamplitude\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamplitude\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# bin sizes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mxpos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcentroid_file\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Pos_X'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'amplitude' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "plt.hist(amplitude, bins=np.arange(min(amplitude), max(amplitude) + 20, 20)) # bin sizes\n",
    "\n",
    "xpos = centroid_file['Pos_X']\n",
    "ypos = centroid_file['Pos_Y']\n",
    "zpos = centroid_file['Pos_Z']\n",
    "\n",
    "array = xpos, ypos, zpos})\n",
    "\n",
    "#plt.hist(amplitude)\n",
    "plt.ylabel('number of spots')\n",
    "plt.xlabel('spot amplitude (gray values)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90.0148\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "\n",
    "# specify the FQ centroid file\n",
    "reference_file = '/Users/joshtitlow/Desktop/airyscan_smFISH_data/20180910_SypeGFP_rRNA_msp_smFISH_stim/aligned/smFISH_channel/_batch/_FISH-QUANT__all_spots_180913.txt'\n",
    "target_file = '/Users/joshtitlow/Desktop/airyscan_smFISH_data/20180903_smFISH/aligned/smFISH_ch/_batch/_FISH-QUANT__all_spots_180904.txt'\n",
    "\n",
    "# read the FQ files from the data header to get centroid positions\n",
    "ref_file = pd.read_csv(reference_file, sep='\\t', header=13)\n",
    "targ_file = pd.read_csv(target_file, sep='\\t', header=13)\n",
    "\n",
    "number = 4\n",
    "ref_amp = ref_file['AMP'].iloc[number]\n",
    "print ref_amp\n",
    "#ref_amp = row[AMP]\n",
    "#target_amp = targetdf[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import spatial\n",
    "import argparse\n",
    "import sys\n",
    "\n",
    "\n",
    "def main(argList):\n",
    "    \n",
    "    parser= argparse.ArgumentParser()\n",
    "    \n",
    "    # specify the FQ centroid files and co-detection distance threshold in nm\n",
    "    parser.add_argument('-ref_file', help='FQ_spots file for reference channel')\n",
    "    parser.add_argument('-target_file', help='FQ_spots file for co-detection')\n",
    "    parser.add_argument('-threshold', help='distance to calculate nearest neighbor')\n",
    "        \n",
    "    args= parser.parse_args(args=argList)\n",
    "    \n",
    "    # specify the FQ centroid files\n",
    "    #reference_file = '/Users/joshtitlow/Desktop/airyscan_smFISH_data/20180910_SypeGFP_rRNA_msp_smFISH_stim/aligned/smFISH_channel/_batch/_FISH-QUANT__all_spots_180913_test1.txt'\n",
    "    #target_file = '/Users/joshtitlow/Desktop/airyscan_smFISH_data/20180910_SypeGFP_rRNA_msp_smFISH_stim/aligned/smFISH_channel/_batch/_FISH-QUANT__all_spots_180913_test2.txt'\n",
    "\n",
    "    # read the FQ files from the data header to get centroid positions\n",
    "    ref_file = pd.read_csv(args.ref_file, sep='\\t', header=13)\n",
    "    targ_file = pd.read_csv(args.target_file, sep='\\t', header=13)\n",
    "\n",
    "    xpos_ref = ref_file['Pos_X']\n",
    "    ypos_ref = ref_file['Pos_Y']\n",
    "    zpos_ref = ref_file['Pos_Z']\n",
    "\n",
    "    xpos_targ = targ_file['Pos_X']\n",
    "    ypos_targ = targ_file['Pos_Y']\n",
    "    zpos_targ = targ_file['Pos_Z']\n",
    "\n",
    "    # convert data into an numpy array\n",
    "    target_df = np.column_stack((xpos_targ,ypos_targ,zpos_targ))\n",
    "\n",
    "    # create list to store amplitude of co-detected spot, ref/targ ratio, and target distance\n",
    "    targ_amp = []\n",
    "    targ_dist = []\n",
    "    \n",
    "    for index, row in ref_file.iterrows():\n",
    "\n",
    "        # get 3D position from X,Y,Z position columns\n",
    "        pt  = row['Pos_X'], row['Pos_Y'], row['Pos_Z']\n",
    "\n",
    "        # find nearest neighbor and calculate distance\n",
    "        distance,index = spatial.KDTree(target_df).query(pt)\n",
    "\n",
    "        # add nearest neighbor amp and dist to a list\n",
    "        targ_amp.append(targ_file['AMP'].iloc[index])\n",
    "        targ_dist.append(distance)\n",
    "\n",
    "    # add lists to ref_file\n",
    "    ref_file['target_amp'] = targ_amp\n",
    "    ref_file['r_t_ratio'] = ref_file['AMP'].div(float(target_amp))\n",
    "    ref_file['targ_dist'] = targ_dist\n",
    "\n",
    "    # calculate co-detection percentage\n",
    "    codetect = 100 * (len(ref_file[ref_file.targ_dist > args.threshold])) / (float(len(ref_file.index)))\n",
    "    print \"Co-detection =\", codetect,\"%\"\n",
    "\n",
    "    # write ref_file to csv\n",
    "    ref_file.to_csv('test_list.csv', index=False)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#indir, outname  = sys.argv[1:]\n",
    "indir = \"/Users/joshtitlow/Clutter_20181109/2color_smFISH/aligned/smFISH_reference_ch1/\"\n",
    "infiles = os.listdir(indir)\n",
    "\n",
    "d = {}\n",
    "\n",
    "for i in infiles:\n",
    "        if not i.startswith('.'):   \n",
    "          thisfile = os.path.join(os.getcwd(), indir, i)\n",
    "          print thisfile\n",
    "          with open(thisfile, 'rb') as f:\n",
    "                  p = pickle.load(f)\n",
    "                  print('thispickle', p)\n",
    "  #       with open(os.path.join(os.getcwd(), indir, i), 'r') as f:\n",
    "          #p = pickle.load(f)\n",
    "                  d[i.rstrip('.pickle')] = p\n",
    "\n",
    "#print(d)\n",
    "df = pd.DataFrame.from_dict(d, orient =  'index')\n",
    "df.to_csv('%s.csv' % outname)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ch1 = 20180105_CS_msp670_570_HRP488_DAPI_p3s3l_TRACHEA_.ome_ALN.ome-1__spots.txt\n",
      "Ch1 = 20180105_CS_msp670_570_HRP488_DAPI_p2s4l.ome_ALN.ome-1__spots.txt\n",
      "Ch1 = 20180105_CS_msp670_570_HRP488_DAPI_p2s3l.ome_ALN.ome-1__spots.txt\n",
      "Ch1 = 20180105_CS_msp670_570_HRP488_DAPI_p1s3l.ome_ALN.ome-1__spots.txt\n",
      "Ch1 = 20180105_CS_msp670_570_HRP488_DAPI_p2s5l.ome_ALN.ome-1__spots.txt\n",
      "Ch1 = 20180105_CS_msp670_570_HRP488_DAPI_p2s5r_GOOD.ome_ALN.ome-1__spots.txt\n",
      "Ch2 = 20180105_CS_msp670_570_HRP488_DAPI_p3s3l_TRACHEA_.ome_ALN.ome-1__spots.txt\n",
      "Ch2 = 20180105_CS_msp670_570_HRP488_DAPI_p2s4l.ome_ALN.ome-1__spots.txt\n",
      "Ch2 = 20180105_CS_msp670_570_HRP488_DAPI_p2s3l.ome_ALN.ome-1__spots.txt\n",
      "Ch2 = 20180105_CS_msp670_570_HRP488_DAPI_p1s3l.ome_ALN.ome-1__spots.txt\n",
      "Ch2 = 20180105_CS_msp670_570_HRP488_DAPI_p2s5l.ome_ALN.ome-1__spots.txt\n",
      "Ch2 = 20180105_CS_msp670_570_HRP488_DAPI_p2s5r_GOOD.ome_ALN.ome-1__spots.txt\n"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "#indir, outname  = sys.argv[1:]\n",
    "ch1_indir = \"/Users/joshtitlow/Clutter_20181109/2color_smFISH/aligned/smFISH_reference_ch1/\"\n",
    "ch2_indir = \"/Users/joshtitlow/Clutter_20181109/2color_smFISH/aligned/smFISH_target_ch2/\"\n",
    "ch1_infiles = os.listdir(ch1_indir)\n",
    "ch2_infiles = os.listdir(ch2_indir)\n",
    "\n",
    "d = {}\n",
    "co_detection = {}\n",
    "ch1_spots = {}\n",
    "ch2_spots = {}\n",
    "\n",
    "for i in ch1_infiles:\n",
    "    if \"1__spots.txt\" in i:\n",
    "        print 'Ch1 =',i\n",
    "for i in ch2_infiles:\n",
    "    if \"1__spots.txt\" in i:\n",
    "        print 'Ch2 =',i\n",
    "\n",
    "df = pd.DataFrame.from_dict(d, orient =  'index')\n",
    "df.to_csv('%s.csv' % outname)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Co-detection = 28.0 %\n"
     ]
    }
   ],
   "source": [
    "thresh = 10000\n",
    "#codetect = 100 * (len(ref_file[ref_file.targ_dist > 10000])) / (float(len(ref_file.index)))\n",
    "codetect = 100 * (len(ref_file[ref_file.targ_dist > thresh])) / (float(len(ref_file.index)))\n",
    "\n",
    "print \"Co-detection =\", codetect,\"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos_Y              70622.9\n",
      "Pos_X              36257.4\n",
      "Pos_Z              4330.94\n",
      "AMP                5554.55\n",
      "BGD                4320.26\n",
      "RES            2.01008e+07\n",
      "SigmaX             125.557\n",
      "SigmaY             125.557\n",
      "SigmaZ              421.44\n",
      "Cent_Y             280.601\n",
      "Cent_X             274.183\n",
      "Cent_Z             614.843\n",
      "MuY                288.867\n",
      "MuX                256.351\n",
      "MuZ                730.938\n",
      "ITERY_det               10\n",
      "Y_det                  509\n",
      "X_det                  262\n",
      "Z_det                   22\n",
      "Y_min                  507\n",
      "Y_max                  511\n",
      "X_min                  260\n",
      "X_max                  264\n",
      "Z_min                   19\n",
      "Z_max                   25\n",
      "INT_raw               9691\n",
      "INT_filt              2149\n",
      "SC_det             466.917\n",
      "SC_det_norm      0.0570487\n",
      "TH_det                   1\n",
      "TH_fit                   1\n",
      "Name: 1267, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reference_file = '/Users/joshtitlow/Desktop/2color_smFISH/aligned/smFISH_reference_ch1/20180105_CS_msp670_570_HRP488_DAPI_p2s3l.ome_ALN.ome-1__spots.txt'\n",
    "#target_file = '/Users/joshtitlow/Desktop/airyscan_smFISH_data/20180910_SypeGFP_rRNA_msp_smFISH_stim/aligned/smFISH_channel/_batch/_FISH-QUANT__all_spots_180913_test2.txt'\n",
    "\n",
    "    \n",
    "ref_file = pd.read_csv(reference_file, sep='\\t', header=18)\n",
    "ref_file = ref_file[:-1]\n",
    "#ref_file[ref_file.Pos_Y != 'SPOTS_END']\n",
    "len(ref_file)\n",
    "print(ref_file.loc[1267])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import argparse\n",
    "import sys\n",
    "\n",
    "co_det_thresh = args.threshold\n",
    "print co_det_thresh\n",
    "\n",
    "def main(argList):\n",
    "    \n",
    "    parser= argparse.ArgumentParser()\n",
    "    parser.add_argument('-ref_file', help='FQ_spots file for reference channel')\n",
    "    parser.add_argument('-target_file', help='FQ_spots file for co-detection')\n",
    "    parser.add_argument('-threshold', help='distance to calculate nearest neighbor')\n",
    "        \n",
    "    args= parser.parse_args(args=argList)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import spatial\n",
    "import numpy as np\n",
    "x = centroid_file['AMP']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/ipykernel/__main__.py:1: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "pixelmean = np.mean([im[data_ch,Z,x0,y0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FQ_file = '/Users/joshtitlow/Desktop/airyscan_smFISH_data/aligned/smFISH_ch/_batch/_FISH-QUANT__all_spots_180904c.txt'\n",
    "centroid_file = pd.read_csv(FQ_file, sep='\\t', header=13)\n",
    "px_size = pd.read_csv(FQ_file, sep='\\t', header=6)\n",
    "px_xy = px_size['Pix-XY'].iloc[0]\n",
    "px_xy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'file' object has no attribute 'head'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-206-9a3012e28bc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'json_data.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w+b'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfilehandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mfilehandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0mfilehandle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'file' object has no attribute 'head'"
     ]
    }
   ],
   "source": [
    "MBtemplate = open ('/Users/joshtitlow/Desktop/DavidGUI/json_Figure/template_json_mb.txt', 'r')\n",
    "linesMB = MBtemplate.readlines()\n",
    "#print(len(lines))\n",
    "m = linesMB[0]\n",
    "\n",
    "with open('json_data.txt', 'w+b') as filehandle:\n",
    "        filehandle.write(m)\n",
    "        filehandle.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint\n",
    "def main():\n",
    "    figure_json = None\n",
    "    #with open(figure_fpath, 'r') as fh:\n",
    "    #   figure_json = json.load(fh)\n",
    "    figure_json = jsonfile\n",
    "    ## This file id should be the file annotation id.  It shouldn't\n",
    "    ## exist yet because we're import a new one.  The only reason to\n",
    "    ## exist is if we were updating an existing figure but we aren't\n",
    "    ## right?\n",
    "    for key in figure_json.items():\n",
    "        if 'fileId' in figure_json:\n",
    "            raise RuntimeError('this figure refers an already existing annotation')\n",
    "        else: \n",
    "            print 'it worked!'  \n",
    "        \n",
    "    name = figure_json['figureName']\n",
    "    ## description of file annotations that were created via the\n",
    "    ## OMERO.figure plugin also include the image ID of the first\n",
    "    ## image on the description.  Don't see the point of that so I'm\n",
    "    ## not doing it.\n",
    "    description = {'name': name}\n",
    "\n",
    "    ## Figures created via the OMERO.figure plugin have a fileId\n",
    "    ## attribute with the file annotation id.  I think we can get away\n",
    "    ## without it.\n",
    "    #file_ann = conn.createFileAnnfromLocalFile(figure_fpath,\n",
    "    #    origFilePathAndName=name, mimetype='application/json',\n",
    "    #    ns='omero.web.figure.json', desc=description)\n",
    "\n",
    "MBtemplate = open ('/Users/joshtitlow/Desktop/DavidGUI/json_Figure/template_json_mb.txt', 'r')\n",
    "linesMB = MBtemplate.readlines()\n",
    "#print(len(lines))\n",
    "m = linesMB[0]\n",
    "\n",
    "with open('jsonfile', 'w') as filehandle:\n",
    "    jsonfile = json.dumps(m, filehandle)\n",
    "    #pprint(jsonfile)\n",
    "#main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "this figure refers an already existing annotation",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-199-d7ce74358721>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'fileId'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'this figure refers an already existing annotation'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mprint\u001b[0m \u001b[0;34m'it worked!'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: this figure refers an already existing annotation"
     ]
    }
   ],
   "source": [
    "MBtemplate = open ('/Users/joshtitlow/Desktop/DavidGUI/json_Figure/template_json_mb.txt', 'r')\n",
    "linesMB = MBtemplate.readlines()\n",
    "#print(len(lines))\n",
    "m = linesMB[0]\n",
    "\n",
    "#with open('/Users/joshtitlow/Desktop/DavidGUI/json_Figure/template_json_mb.txt') as f:\n",
    "json_data = json.loads(m)\n",
    "\n",
    "for key, value in json_data.items():\n",
    "    if json_data.has_key('fileId'):\n",
    "        raise RuntimeError('this figure refers an already existing annotation')\n",
    "    else: \n",
    "        print 'it worked!'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No JSON object could be decoded",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-187-ebf606002a8c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'jsonfile.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfilehandle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMBtemplate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilehandle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mjfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMBtemplate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m//anaconda/lib/python2.7/json/__init__.pyc\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, encoding, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    337\u001b[0m             \u001b[0mparse_int\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mparse_float\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 339\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mJSONDecoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \"\"\"\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m//anaconda/lib/python2.7/json/decoder.pyc\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    380\u001b[0m             \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscan_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No JSON object could be decoded\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No JSON object could be decoded"
     ]
    }
   ],
   "source": [
    "MBtemplate = json.loads(/Users/joshtitlow/Desktop/DavidGUI/json_Figure/template_json_mb.txt)\n",
    "for key, value in MBtemplate.items():\n",
    "    \n",
    "#linesMB = MBtemplate.readlines()\n",
    "#print(len(lines))\n",
    "#m = linesMB[0]\n",
    "#with open('jsonfile.txt', 'w') as filehandle:\n",
    "#    json.dumps(MBtemplate, filehandle)\n",
    "#    jfile = json.loads(MBtemplate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "393\n",
      "106\n",
      "131\n",
      "220\n",
      "156\n",
      "256\n",
      "147\n",
      "195\n",
      "117\n",
      "183\n",
      "110\n",
      "185\n",
      "280\n",
      "469\n",
      "398\n",
      "396\n",
      "305\n",
      "824\n",
      "453\n",
      "111\n",
      "357\n",
      "349\n",
      "397\n",
      "452\n",
      "523\n",
      "231\n",
      "250\n",
      "165\n",
      "346\n",
      "504\n",
      "436\n",
      "221\n",
      "460\n",
      "310\n",
      "611\n",
      "225\n",
      "162\n",
      "369\n",
      "171\n",
      "170\n",
      "253\n",
      "100\n",
      "169\n",
      "412\n",
      "252\n",
      "255\n",
      "110\n",
      "309\n",
      "249\n",
      "142\n",
      "307\n",
      "620\n",
      "290\n",
      "498\n",
      "363\n",
      "339\n",
      "168\n",
      "130\n",
      "340\n",
      "350\n",
      "248\n",
      "372\n",
      "330\n",
      "248\n",
      "645\n",
      "312\n",
      "350\n",
      "335\n",
      "477\n",
      "369\n",
      "774\n",
      "413\n",
      "982\n",
      "249\n",
      "246\n",
      "499\n",
      "142\n",
      "271\n",
      "254\n",
      "89\n",
      "373\n",
      "396\n",
      "273\n",
      "153\n",
      "315\n",
      "378\n",
      "483\n",
      "224\n",
      "443\n",
      "264\n",
      "341\n",
      "192\n",
      "595\n",
      "641\n",
      "235\n",
      "160\n",
      "111\n",
      "117\n",
      "218\n",
      "184\n",
      "183\n",
      "141\n",
      "200\n",
      "151\n",
      "76\n",
      "167\n",
      "128\n",
      "76\n",
      "190\n",
      "249\n",
      "228\n",
      "190\n",
      "237\n",
      "145\n",
      "169\n",
      "238\n",
      "193\n",
      "156\n",
      "111\n",
      "184\n",
      "149\n",
      "93\n",
      "228\n",
      "160\n",
      "77\n",
      "147\n",
      "151\n",
      "67\n",
      "106\n",
      "190\n",
      "160\n",
      "78\n",
      "154\n",
      "112\n",
      "162\n",
      "189\n",
      "138\n",
      "81\n",
      "114\n",
      "240\n",
      "90\n",
      "220\n",
      "75\n",
      "233\n",
      "237\n",
      "155\n",
      "175\n",
      "92\n",
      "179\n",
      "74\n",
      "77\n",
      "236\n",
      "180\n",
      "100\n",
      "115\n",
      "165\n",
      "174\n",
      "101\n",
      "88\n",
      "243\n",
      "224\n",
      "154\n",
      "203\n",
      "190\n",
      "237\n",
      "171\n",
      "87\n",
      "94\n",
      "111\n",
      "143\n",
      "183\n",
      "172\n",
      "251\n",
      "182\n",
      "90\n",
      "145\n",
      "147\n",
      "287\n",
      "171\n",
      "220\n",
      "190\n",
      "252\n",
      "238\n",
      "140\n",
      "271\n",
      "107\n",
      "299\n",
      "154\n",
      "139\n",
      "181\n",
      "299\n",
      "213\n",
      "244\n",
      "199\n",
      "104\n",
      "199\n",
      "216\n",
      "223\n",
      "365\n",
      "253\n",
      "84\n",
      "215\n",
      "124\n",
      "138\n",
      "138\n",
      "333\n",
      "257\n",
      "105\n",
      "275\n",
      "120\n",
      "178\n",
      "223\n",
      "178\n",
      "65\n",
      "183\n",
      "69\n",
      "72\n",
      "120\n",
      "81\n",
      "81\n",
      "81\n",
      "138\n",
      "89\n",
      "74\n",
      "145\n",
      "90\n",
      "109\n",
      "84\n",
      "103\n",
      "139\n",
      "110\n",
      "86\n",
      "101\n",
      "131\n",
      "176\n",
      "237\n",
      "169\n",
      "116\n",
      "144\n",
      "229\n",
      "264\n",
      "176\n",
      "88\n",
      "129\n",
      "104\n",
      "230\n",
      "258\n",
      "213\n",
      "229\n",
      "154\n",
      "257\n",
      "154\n",
      "219\n",
      "371\n",
      "89\n",
      "188\n",
      "144\n",
      "220\n",
      "229\n",
      "335\n",
      "220\n",
      "148\n",
      "227\n",
      "235\n",
      "134\n",
      "203\n",
      "133\n",
      "221\n",
      "228\n",
      "130\n",
      "222\n",
      "299\n",
      "162\n",
      "178\n",
      "175\n",
      "218\n",
      "235\n",
      "178\n",
      "185\n",
      "241\n",
      "188\n",
      "117\n",
      "129\n",
      "259\n",
      "200\n",
      "213\n",
      "164\n",
      "148\n",
      "250\n",
      "69\n",
      "149\n",
      "125\n",
      "267\n",
      "116\n",
      "163\n",
      "72\n",
      "64\n",
      "86\n",
      "65\n",
      "286\n",
      "110\n",
      "134\n",
      "140\n",
      "79\n",
      "137\n",
      "132\n",
      "98\n",
      "103\n",
      "144\n",
      "126\n",
      "249\n",
      "260\n",
      "135\n",
      "213\n",
      "91\n",
      "93\n",
      "207\n",
      "165\n",
      "128\n",
      "165\n",
      "188\n",
      "154\n",
      "117\n",
      "218\n",
      "111\n",
      "166\n",
      "142\n",
      "93\n",
      "124\n",
      "267\n",
      "277\n",
      "133\n",
      "226\n",
      "108\n",
      "110\n",
      "174\n",
      "157\n",
      "163\n",
      "159\n",
      "192\n",
      "106\n",
      "237\n",
      "250\n",
      "257\n",
      "264\n",
      "137\n",
      "114\n",
      "133\n",
      "159\n",
      "164\n",
      "194\n",
      "117\n",
      "126\n",
      "171\n",
      "86\n",
      "83\n",
      "159\n",
      "107\n",
      "234\n",
      "174\n",
      "139\n",
      "241\n",
      "79\n",
      "96\n",
      "126\n",
      "207\n",
      "109\n",
      "86\n",
      "71\n",
      "149\n",
      "206\n",
      "163\n",
      "171\n",
      "80\n",
      "139\n",
      "57\n",
      "78\n",
      "116\n",
      "159\n",
      "95\n",
      "103\n",
      "109\n",
      "142\n",
      "115\n",
      "99\n",
      "123\n",
      "99\n",
      "207\n",
      "142\n",
      "170\n",
      "79\n",
      "100\n",
      "131\n",
      "81\n",
      "123\n",
      "83\n",
      "103\n",
      "194\n",
      "77\n",
      "133\n",
      "82\n",
      "152\n",
      "115\n",
      "81\n",
      "152\n",
      "107\n",
      "177\n",
      "112\n",
      "98\n",
      "80\n",
      "168\n",
      "87\n",
      "163\n",
      "110\n",
      "71\n",
      "105\n",
      "61\n",
      "135\n",
      "61\n",
      "108\n",
      "74\n",
      "57\n",
      "109\n",
      "78\n",
      "96\n",
      "126\n",
      "182\n",
      "91\n",
      "80\n",
      "64\n",
      "60\n",
      "69\n",
      "73\n",
      "64\n",
      "73\n",
      "64\n",
      "86\n",
      "74\n",
      "71\n",
      "75\n",
      "61\n",
      "80\n",
      "62\n",
      "57\n",
      "68\n",
      "75\n",
      "82\n",
      "89\n",
      "66\n",
      "61\n",
      "78\n",
      "66\n",
      "67\n",
      "80\n",
      "59\n",
      "69\n",
      "61\n",
      "97\n",
      "77\n",
      "97\n",
      "69\n",
      "70\n",
      "73\n",
      "75\n",
      "68\n",
      "93\n",
      "67\n",
      "89\n",
      "75\n",
      "58\n",
      "81\n",
      "62\n",
      "77\n",
      "72\n",
      "80\n",
      "87\n",
      "81\n",
      "90\n",
      "77\n",
      "103\n",
      "74\n",
      "372\n",
      "295\n",
      "128\n",
      "113\n",
      "106\n",
      "231\n",
      "61\n",
      "285\n",
      "228\n",
      "166\n",
      "137\n",
      "177\n",
      "182\n",
      "111\n",
      "299\n",
      "142\n",
      "188\n",
      "250\n",
      "149\n",
      "129\n",
      "189\n",
      "237\n",
      "104\n",
      "168\n",
      "201\n",
      "263\n",
      "167\n",
      "142\n",
      "190\n",
      "75\n",
      "85\n",
      "89\n",
      "47\n",
      "84\n",
      "102\n",
      "90\n",
      "225\n",
      "56\n",
      "228\n",
      "78\n",
      "95\n",
      "210\n",
      "108\n",
      "117\n",
      "109\n",
      "83\n",
      "219\n",
      "84\n",
      "119\n",
      "171\n",
      "88\n",
      "164\n",
      "128\n",
      "68\n",
      "85\n",
      "267\n",
      "93\n",
      "247\n",
      "252\n",
      "186\n",
      "327\n",
      "53\n",
      "169\n",
      "114\n",
      "96\n",
      "62\n",
      "103\n",
      "115\n",
      "215\n",
      "261\n",
      "104\n",
      "218\n",
      "180\n",
      "193\n",
      "82\n",
      "82\n",
      "216\n",
      "322\n",
      "212\n",
      "89\n",
      "124\n",
      "126\n",
      "68\n",
      "215\n",
      "233\n",
      "250\n",
      "191\n",
      "178\n",
      "138\n",
      "99\n",
      "121\n",
      "222\n",
      "150\n",
      "100\n",
      "93\n",
      "190\n",
      "93\n",
      "133\n",
      "68\n",
      "195\n",
      "214\n",
      "191\n",
      "163\n",
      "91\n",
      "137\n",
      "198\n",
      "236\n",
      "176\n",
      "115\n",
      "154\n",
      "186\n",
      "160\n",
      "163\n",
      "92\n",
      "255\n",
      "154\n",
      "162\n",
      "124\n",
      "284\n",
      "69\n",
      "135\n",
      "98\n",
      "84\n",
      "81\n",
      "113\n",
      "39\n",
      "81\n",
      "69\n",
      "75\n",
      "66\n",
      "78\n",
      "67\n",
      "129\n",
      "65\n",
      "83\n",
      "64\n",
      "50\n",
      "46\n",
      "53\n",
      "41\n",
      "39\n",
      "22\n",
      "66\n",
      "49\n",
      "52\n",
      "54\n",
      "25\n",
      "75\n",
      "41\n",
      "77\n",
      "38\n",
      "35\n",
      "84\n",
      "48\n",
      "56\n",
      "53\n",
      "65\n",
      "27\n",
      "55\n",
      "27\n",
      "76\n",
      "47\n",
      "63\n",
      "45\n",
      "81\n",
      "71\n",
      "81\n",
      "63\n",
      "63\n",
      "26\n",
      "22\n",
      "47\n",
      "45\n",
      "56\n",
      "40\n",
      "76\n",
      "48\n",
      "59\n",
      "45\n",
      "22\n",
      "125\n",
      "44\n",
      "51\n",
      "113\n",
      "91\n",
      "35\n",
      "54\n",
      "64\n",
      "60\n",
      "73\n",
      "89\n",
      "57\n",
      "108\n",
      "184\n",
      "85\n",
      "80\n",
      "133\n",
      "80\n",
      "73\n",
      "59\n",
      "100\n",
      "75\n",
      "61\n",
      "78\n",
      "106\n",
      "75\n",
      "86\n",
      "48\n",
      "63\n",
      "51\n",
      "76\n",
      "91\n",
      "78\n",
      "87\n",
      "78\n",
      "79\n",
      "87\n",
      "73\n",
      "57\n",
      "54\n",
      "89\n",
      "97\n",
      "52\n",
      "89\n",
      "72\n",
      "89\n",
      "71\n",
      "56\n",
      "76\n",
      "74\n",
      "87\n",
      "75\n",
      "80\n",
      "63\n",
      "87\n",
      "62\n",
      "99\n",
      "87\n",
      "78\n",
      "107\n",
      "98\n",
      "104\n",
      "100\n",
      "94\n",
      "96\n",
      "141\n",
      "87\n",
      "76\n",
      "97\n",
      "42\n",
      "39\n",
      "51\n",
      "58\n",
      "66\n",
      "69\n",
      "66\n",
      "33\n",
      "51\n",
      "59\n",
      "36\n",
      "63\n",
      "82\n",
      "81\n",
      "83\n",
      "49\n",
      "83\n",
      "50\n",
      "67\n",
      "70\n",
      "79\n",
      "46\n",
      "57\n",
      "57\n",
      "55\n",
      "82\n",
      "58\n",
      "57\n",
      "52\n",
      "42\n",
      "57\n",
      "59\n",
      "76\n",
      "69\n",
      "51\n",
      "121\n",
      "80\n",
      "75\n",
      "58\n",
      "55\n",
      "49\n",
      "70\n",
      "61\n",
      "73\n",
      "53\n",
      "71\n",
      "34\n",
      "53\n",
      "62\n",
      "53\n",
      "90\n",
      "40\n",
      "78\n",
      "68\n",
      "68\n",
      "58\n",
      "60\n",
      "73\n",
      "83\n",
      "43\n",
      "61\n",
      "43\n",
      "71\n",
      "49\n",
      "33\n",
      "48\n",
      "77\n",
      "69\n",
      "52\n",
      "55\n",
      "49\n",
      "77\n",
      "67\n",
      "59\n",
      "55\n",
      "59\n",
      "68\n",
      "54\n",
      "51\n",
      "60\n",
      "49\n",
      "51\n",
      "70\n",
      "44\n",
      "45\n",
      "48\n",
      "72\n",
      "80\n",
      "49\n",
      "56\n",
      "49\n",
      "0\n",
      "60\n",
      "82\n",
      "54\n",
      "96\n",
      "49\n",
      "66\n",
      "84\n",
      "96\n",
      "65\n",
      "53\n",
      "79\n",
      "57\n",
      "93\n",
      "69\n",
      "69\n",
      "84\n",
      "91\n",
      "71\n",
      "63\n",
      "66\n",
      "70\n",
      "76\n",
      "76\n",
      "86\n",
      "50\n",
      "66\n",
      "71\n",
      "57\n",
      "63\n",
      "62\n",
      "78\n",
      "64\n",
      "98\n",
      "69\n",
      "58\n",
      "66\n",
      "78\n",
      "65\n",
      "78\n",
      "57\n",
      "66\n",
      "78\n",
      "60\n",
      "74\n",
      "294\n",
      "382\n",
      "304\n",
      "213\n",
      "350\n",
      "317\n",
      "300\n",
      "298\n",
      "257\n",
      "276\n",
      "338\n",
      "200\n",
      "326\n",
      "291\n",
      "233\n",
      "264\n",
      "298\n",
      "258\n",
      "401\n",
      "279\n",
      "168\n",
      "190\n",
      "386\n",
      "386\n",
      "108\n",
      "131\n",
      "264\n",
      "123\n",
      "256\n",
      "282\n",
      "371\n",
      "183\n",
      "173\n",
      "148\n",
      "336\n",
      "195\n",
      "436\n",
      "193\n",
      "415\n",
      "310\n",
      "288\n",
      "165\n",
      "270\n",
      "166\n",
      "94\n",
      "110\n",
      "80\n",
      "153\n",
      "94\n",
      "92\n",
      "92\n",
      "72\n",
      "107\n",
      "65\n",
      "67\n",
      "178\n",
      "66\n",
      "121\n",
      "118\n",
      "93\n",
      "60\n",
      "89\n",
      "121\n",
      "107\n",
      "66\n",
      "110\n",
      "83\n",
      "145\n",
      "59\n",
      "117\n",
      "64\n",
      "66\n",
      "154\n",
      "107\n",
      "91\n",
      "78\n",
      "91\n",
      "120\n",
      "64\n",
      "117\n",
      "116\n",
      "62\n",
      "143\n",
      "88\n",
      "76\n",
      "98\n",
      "65\n",
      "112\n",
      "137\n",
      "95\n",
      "155\n",
      "100\n",
      "110\n",
      "182\n",
      "80\n",
      "158\n",
      "106\n",
      "86\n",
      "70\n",
      "102\n",
      "213\n",
      "197\n",
      "66\n",
      "142\n",
      "105\n",
      "152\n",
      "105\n",
      "111\n",
      "89\n",
      "189\n",
      "192\n",
      "297\n",
      "118\n",
      "164\n",
      "148\n",
      "155\n",
      "143\n",
      "94\n",
      "226\n",
      "207\n",
      "157\n",
      "284\n",
      "233\n",
      "204\n",
      "180\n",
      "183\n",
      "231\n",
      "185\n",
      "210\n",
      "327\n",
      "203\n",
      "250\n",
      "246\n",
      "218\n",
      "212\n",
      "333\n",
      "268\n",
      "181\n",
      "205\n",
      "283\n",
      "312\n",
      "355\n",
      "279\n",
      "259\n",
      "305\n",
      "58\n",
      "237\n",
      "205\n",
      "293\n",
      "198\n",
      "259\n",
      "279\n",
      "278\n",
      "298\n",
      "122\n",
      "184\n",
      "272\n",
      "174\n",
      "180\n",
      "290\n",
      "170\n",
      "162\n",
      "128\n",
      "308\n",
      "154\n",
      "153\n",
      "125\n",
      "280\n",
      "165\n",
      "280\n",
      "218\n",
      "164\n",
      "185\n",
      "191\n",
      "163\n",
      "389\n",
      "164\n",
      "288\n",
      "264\n",
      "238\n",
      "263\n",
      "66\n",
      "172\n",
      "348\n",
      "109\n",
      "274\n",
      "217\n",
      "134\n",
      "219\n",
      "127\n",
      "193\n",
      "197\n",
      "126\n",
      "47\n",
      "85\n",
      "125\n",
      "244\n",
      "244\n",
      "184\n",
      "437\n",
      "165\n",
      "242\n",
      "323\n",
      "244\n",
      "453\n",
      "482\n",
      "565\n",
      "322\n",
      "414\n",
      "467\n",
      "475\n",
      "420\n",
      "413\n",
      "474\n",
      "576\n",
      "662\n",
      "604\n",
      "325\n",
      "301\n",
      "269\n",
      "279\n",
      "445\n",
      "371\n",
      "306\n",
      "352\n",
      "385\n",
      "267\n",
      "297\n",
      "286\n",
      "347\n",
      "354\n",
      "333\n",
      "75\n",
      "416\n",
      "307\n",
      "333\n",
      "339\n",
      "262\n",
      "575\n",
      "316\n",
      "212\n",
      "253\n",
      "271\n",
      "266\n",
      "560\n",
      "338\n",
      "239\n",
      "456\n",
      "528\n",
      "247\n",
      "290\n",
      "208\n",
      "85\n",
      "503\n",
      "273\n",
      "75\n",
      "270\n",
      "164\n",
      "209\n",
      "73\n"
     ]
    }
   ],
   "source": [
    "# Script to analyse single pixel intensities relative to centroids\n",
    "# Created: 2 August 2018\n",
    "\n",
    "# Worflow overview\n",
    "# > Acquire super resolution data of smFISH and a correlated signal (e.g., IHC or in this case another smFISH target)\n",
    "# > Perform registration with Chromagnon\n",
    "# > Use FISH-Quant to generate a .csv file of centroid positions from smFISH signal (Batch>SaveThresolded spots)\n",
    "#     > Convert the position coordinates to integer pixel values (used Excel but could write this with Python) \n",
    "# > Generate a single channel z-stack of the signal to be correlated with centroid positions\n",
    "# > Run this script which does the following:\n",
    "#     > Open a .csv of centroid positions (have to check if 'raw' FQ output files can be analysed, was an issue with \n",
    "#       where series of integers had to be added to the lefthand column)\n",
    "#     > Iterate through each row and get the image file name from the File_name column\n",
    "#     > Use scikit-image to open the .tiff as a 3D numpy array\n",
    "#     > Pass the pixel values as variables to scikit-image object to get the intensity value\n",
    "#\n",
    "# TO DO\n",
    "# \n",
    "# Fix file_name heading \n",
    "# Consider alternative normalisation routines\n",
    "# Append pixel values to the FQ .csv file (currently the list is printed and copied from the notebook)\n",
    "# \n",
    "\n",
    "import os\n",
    "from skimage import io\n",
    "import pandas as pd\n",
    "\n",
    "image_dir ='/Users/joshtitlow/Desktop/airyscan/images/rRNA_not_normalised/'\n",
    "image_names = [i for i in os.listdir(image_dir) if i.endswith('.tif')]\n",
    "\n",
    "centroid_file = pd.read_csv('/Users/joshtitlow/Desktop/airyscan/images/images/_batch/_FISH-QUANT__all_spots_180801.csv', header=13)\n",
    "\n",
    "for index, row in centroid_file.iterrows():\n",
    "    file =row['File']\n",
    "    im = io.imread(image_dir+file)\n",
    "    #print im.shape\n",
    "    Y = row['Y_pix'] \n",
    "    X = row['X_pix']\n",
    "    Z1 = row['Z_pixAb']\n",
    "    Z2 = row['Z_pixBl']\n",
    "    pixel = im[Z2,Y,X]\n",
    "    print(pixel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
